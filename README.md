# Data-factory-with-Devops

This project demonstrates a solution in Azure Fabric with 3 pipelines that takes 3 different data sources and extracts the data to an azure DataLake container clasified as a bronze layer.


![image](https://github.com/assets/DataFactory.png/)

## ðŸ“– Project Overview
This project involves:

1. **Api_ingestion**: extracting data from Github.
2. **On premises ingestion**: Extracting csv files from a computer)
3. **SQL ingestion*: database ingestion with incrementing loading, it takes a table and migrate the table based on a date parameter.


   
#### Objective
Develop a parent Pipeline that contains the 3 pipelines described before. Extracts the data to load it into an azure DataLake over the bronze layer container.

#### Specifications
- **Data Sources**: 
- **Data Quality**: 
- **Integration**: 
- **Scope**: 
- **Documentation**: Provide clear documentation of the data model to support both business stakeholders and analytics teams.
